{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "model = YOLO('yolov8n-pose.pt')\n",
    "\n",
    "directory_path = '/home/mind/projects/projects/action_recognition/data'\n",
    "\n",
    "df = pd.DataFrame(columns=['Nose_x', 'Nose_y', 'Left-eye_x', 'Left-eye_y', 'Right-eye_x', 'Right-eye_y', 'Left-ear_x', 'Left-ear_y','Right-ear_x', 'Right-ear_y', 'Left-shoulder_x', 'Left-shoulder_y', 'Right-shoulder_x', 'Right-shoulder_y', 'Left-elbow_x', 'Left-elbow_y', 'Right-elbow_x', 'Right-elbow_y', 'Left-wrist_x', 'Left-wrist_y', 'Right-wrist_x', 'Right-wrist_y', 'Left-hip_x', 'Left-hip_y', 'Right-hip_x', 'Right-hip_y', 'Left-knee_x', 'Left-knee_y', 'Right-knee_x', 'Right-knee_y', 'Left-ankle_x', 'Left-ankle_y', 'Right-ankle_x', 'Right-ankle_y', 'Class'])\n",
    "\n",
    "for sub_directory in os.listdir(directory_path):\n",
    "\n",
    "    sub_directory_path = os.path.join(directory_path, sub_directory)\n",
    "    if sub_directory.lower() == 'standing':\n",
    "        # class_encoding = np.array([1,0,0])\n",
    "        class_encoding = 0\n",
    "    elif sub_directory.lower() == 'falling':\n",
    "        # class_encoding = np.array([0,1,0])\n",
    "        class_encoding = 1\n",
    "    elif sub_directory.lower() == 'walking':\n",
    "        # class_encoding = np.array([0,0,1])\n",
    "        class_encoding = 2\n",
    "\n",
    "    for image in os.listdir(sub_directory_path):\n",
    "        image_path = os.path.join(sub_directory_path, image)\n",
    "        # img = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.imread(image_path)\n",
    "        # plt.imshow(img)\n",
    "        # plt.show()\n",
    "        results = model(source=img,\n",
    "                show=False,\n",
    "                conf=0.3,\n",
    "                save=False,\n",
    "                verbose=False,\n",
    "                stream=True,\n",
    "        )\n",
    "        for result in results:\n",
    "            keypoints = result.keypoints.xyn[0].numpy()\n",
    "            df.loc[len(df.index)] = [keypoints[0][0],\n",
    "                                     keypoints[0][1],\n",
    "                                     keypoints[1][0],\n",
    "                                     keypoints[1][1],\n",
    "                                     keypoints[2][0],\n",
    "                                     keypoints[2][1],\n",
    "                                     keypoints[3][0],\n",
    "                                     keypoints[3][1],\n",
    "                                     keypoints[4][0],\n",
    "                                     keypoints[4][1],\n",
    "                                     keypoints[5][0],\n",
    "                                     keypoints[5][1],\n",
    "                                     keypoints[6][0],\n",
    "                                     keypoints[6][1],\n",
    "                                     keypoints[7][0],\n",
    "                                     keypoints[7][1],\n",
    "                                     keypoints[8][0],\n",
    "                                     keypoints[8][1],\n",
    "                                     keypoints[9][0],\n",
    "                                     keypoints[9][1],\n",
    "                                     keypoints[10][0],\n",
    "                                     keypoints[10][1],\n",
    "                                     keypoints[11][0],\n",
    "                                     keypoints[11][1],\n",
    "                                     keypoints[12][0],\n",
    "                                     keypoints[12][1],\n",
    "                                     keypoints[13][0],\n",
    "                                     keypoints[13][1],\n",
    "                                     keypoints[14][0],\n",
    "                                     keypoints[14][1],\n",
    "                                     keypoints[15][0],\n",
    "                                     keypoints[15][1],\n",
    "                                     keypoints[16][0],\n",
    "                                     keypoints[16][1],\n",
    "                                     class_encoding]  \n",
    "   \n",
    "    print('----------------------------------------------------------------------------------')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac = 1, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df.drop(columns='Class')\n",
    "y_train = df['Class']\n",
    "print(x_train, y_train)\n",
    "\n",
    "# x_train = df.iloc[:, :17].values\n",
    "# y_train = df.iloc[:, -1].values\n",
    "# print(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.iloc[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=0.5)\n",
    "clf = svc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = model(source='test_data/standing0.jpg',\n",
    "#                 show=False,\n",
    "#                 conf=0.3,\n",
    "#                 save=False,\n",
    "#                 verbose=False,\n",
    "#                 stream=True,\n",
    "#         )\n",
    "\n",
    "# for output in outputs:\n",
    "#     output_keypoints = output.keypoints.xyn.numpy()\n",
    "#     # print(output_keypoints)\n",
    "\n",
    "# prediction = clf.predict(output_keypoints.flatten().reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('/home/mind/projects/projects/action_recognition/test_data/pexels-kampus-production-8711342 (720p).mp4')\n",
    "\n",
    "if (cap.isOpened() == False):\n",
    "    print('Error while trying to read video. Please check path again')\n",
    "\n",
    "while(cap.isOpened):\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "\n",
    "        outputs = model(source=frame,\n",
    "                show=False,\n",
    "                conf=0.3,\n",
    "                save=False,\n",
    "                verbose=False,\n",
    "                stream=True,\n",
    "        )\n",
    "\n",
    "        for output in outputs:\n",
    "            output_keypoints = output.keypoints.xyn.numpy()\n",
    "        \n",
    "        # print(len(output_keypoints[0]))\n",
    "        \n",
    "        text = ''\n",
    "        flag = False\n",
    "\n",
    "        if len(output_keypoints[0]) == 17:\n",
    "            prediction = clf.predict(output_keypoints[0].flatten().reshape(1, -1))\n",
    "            flag = True\n",
    "            # print(prediction[0])\n",
    "        # else:\n",
    "        #     text = ''\n",
    "\n",
    "        if flag:\n",
    "            if prediction[0] == float(0):\n",
    "                text = 'standing'\n",
    "            elif prediction[0] == float(1):\n",
    "                text = 'falling'\n",
    "            elif prediction[0] == float(2):\n",
    "                text = 'walking'\n",
    "\n",
    "        frame = cv2.putText(frame.copy(), text, (425, 100), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1.5, color=[0, 0, 255], thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('output', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "                break\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "action_recognition_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
